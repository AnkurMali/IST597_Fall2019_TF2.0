{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN_week9.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H6iAa0qJHef7",
        "colab_type": "text"
      },
      "source": [
        "IST597 :- Implementing CNN from scratch\n",
        "Week 9 Tutorial"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9RIMwQ1kVCAM",
        "colab_type": "text"
      },
      "source": [
        "Author:- aam35"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "blypua5fHd4Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import time\n",
        "import tensorflow.contrib.eager as tfe\n",
        "tf.enable_eager_execution()\n",
        "tf.executing_eagerly()\n",
        "seed = 1234\n",
        "tf.random.set_random_seed(seed=seed)\n",
        "np.random.seed(seed)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PmBuZhOxICY7",
        "colab_type": "code",
        "outputId": "4164ffeb-cdb6-40a9-d30b-89e471e0aedb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        }
      },
      "source": [
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "data = input_data.read_data_sets(\"/tmp/data/\", one_hot=True, reshape=False)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
            "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
            "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
            "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FT60sFMCIHrK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 64\n",
        "hidden_size = 100\n",
        "learning_rate = 0.01\n",
        "output_size = 10"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Qvl8f3HS7Hw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CNN(object):\n",
        "  def __init__(self,hidden_size,output_size,device=None):\n",
        "      filter_h, filter_w, filter_c , filter_n = 5 ,5 ,1 ,30\n",
        "      self.W1 = tf.Variable(tf.random_normal([filter_h, filter_w, filter_c, filter_n], stddev=0.01))\n",
        "      self.b1 = tf.Variable(tf.zeros([filter_n]),dtype=tf.float32)\n",
        "      self.W2 = tf.Variable(tf.random_normal([14*14*filter_n, hidden_size], stddev=0.01))\n",
        "      self.b2 = tf.Variable(tf.zeros([hidden_size]),dtype=tf.float32)\n",
        "      self.W3 = tf.Variable(tf.random_normal([hidden_size, output_size], stddev=0.01))\n",
        "      self.b3 = tf.Variable(tf.zeros([output_size]),dtype=tf.float32)\n",
        "      self.variables = [self.W1,self.b1, self.W2, self.b2, self.W3, self.b3]\n",
        "      self.device = device\n",
        "      self.size_output = output_size\n",
        "  \n",
        "  def flatten(self,X, window_h, window_w, window_c, out_h, out_w, stride=1, padding=0):\n",
        "    \n",
        "      X_padded = tf.pad(X, [[0,0], [padding, padding], [padding, padding], [0,0]])\n",
        "\n",
        "      windows = []\n",
        "      for y in range(out_h):\n",
        "          for x in range(out_w):\n",
        "              window = tf.slice(X_padded, [0, y*stride, x*stride, 0], [-1, window_h, window_w, -1])\n",
        "              windows.append(window)\n",
        "      stacked = tf.stack(windows) # shape : [out_h, out_w, n, filter_h, filter_w, c]\n",
        "\n",
        "      return tf.reshape(stacked, [-1, window_c*window_w*window_h])\n",
        "  \n",
        "  def convolution(self,X, W, b, padding, stride):\n",
        "      n, h, w, c = map(lambda d: d.value, X.get_shape())\n",
        "      #print(X.get_shape())\n",
        "      #print(data.train.images.get_shape())\n",
        "      filter_h, filter_w, filter_c, filter_n = [d.value for d in W.get_shape()]\n",
        "    \n",
        "      out_h = (h + 2*padding - filter_h)//stride + 1\n",
        "      out_w = (w + 2*padding - filter_w)//stride + 1\n",
        "\n",
        "      X_flat = self.flatten(X, filter_h, filter_w, filter_c, out_h, out_w, stride, padding)\n",
        "      W_flat = tf.reshape(W, [filter_h*filter_w*filter_c, filter_n])\n",
        "    \n",
        "      z = tf.matmul(X_flat, W_flat) + b     # b: 1 X filter_n\n",
        "    \n",
        "      return tf.transpose(tf.reshape(z, [out_h, out_w, n, filter_n]), [2, 0, 1, 3])\n",
        "    \n",
        " \n",
        "    \n",
        "  def relu(self,X):\n",
        "      return tf.maximum(X, tf.zeros_like(X))\n",
        "    \n",
        "  def max_pool(self,X, pool_h, pool_w, padding, stride):\n",
        "      n, h, w, c = [d.value for d in X.get_shape()]\n",
        "    \n",
        "      out_h = (h + 2*padding - pool_h)//stride + 1\n",
        "      out_w = (w + 2*padding - pool_w)//stride + 1\n",
        "\n",
        "      X_flat = self.flatten(X, pool_h, pool_w, c, out_h, out_w, stride, padding)\n",
        "\n",
        "      pool = tf.reduce_max(tf.reshape(X_flat, [out_h, out_w, n, pool_h*pool_w, c]), axis=3)\n",
        "      return tf.transpose(pool, [2, 0, 1, 3])\n",
        "\n",
        "    \n",
        "  def affine(self,X, W, b):\n",
        "      n = X.get_shape()[0].value # number of samples\n",
        "      X_flat = tf.reshape(X, [n, -1])\n",
        "      return tf.matmul(X_flat, W) + b \n",
        "    \n",
        "  def softmax(self,X):\n",
        "      X_centered = X - tf.reduce_max(X) # to avoid overflow\n",
        "      X_exp = tf.exp(X_centered)\n",
        "      exp_sum = tf.reduce_sum(X_exp, axis=1)\n",
        "      return tf.transpose(tf.transpose(X_exp) / exp_sum) \n",
        "    \n",
        "  \n",
        "  def cross_entropy_error(self,yhat, y):\n",
        "      return -tf.reduce_mean(tf.log(tf.reduce_sum(yhat * y, axis=1)))\n",
        "    \n",
        "  \n",
        "  def forward(self,X):\n",
        "      if self.device is not None:\n",
        "        with tf.device('gpu:0' if self.device == 'gpu' else 'cpu'):\n",
        "          self.y = self.compute_output(X)\n",
        "      else:\n",
        "        self.y = self.compute_output(X)\n",
        "      \n",
        "      return self.y\n",
        "    \n",
        "    \n",
        "  def loss(self, y_pred, y_true):\n",
        "      '''\n",
        "      y_pred - Tensor of shape (batch_size, size_output)\n",
        "      y_true - Tensor of shape (batch_size, size_output)\n",
        "      '''\n",
        "      y_true_tf = tf.cast(tf.reshape(y_true, (-1, self.size_output)), dtype=tf.float32)\n",
        "      y_pred_tf = tf.cast(y_pred, dtype=tf.float32)\n",
        "      return tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=y_pred_tf, labels=y_true_tf))\n",
        "    \n",
        "    \n",
        "  def backward(self, X_train, y_train):\n",
        "      \"\"\"\n",
        "      backward pass\n",
        "      \"\"\"\n",
        "      # optimizer\n",
        "      # Test with SGD,Adam, RMSProp\n",
        "      optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
        "      #predicted = self.forward(X_train)\n",
        "      #current_loss = self.loss(predicted, y_train)\n",
        "      #optimizer.minimize(current_loss, self.variables)\n",
        "\n",
        "      #optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
        "      with tf.GradientTape() as tape:\n",
        "          predicted = self.forward(X_train)\n",
        "          current_loss = self.loss(predicted, y_train)\n",
        "      #print(predicted)\n",
        "      #print(current_loss)\n",
        "      #current_loss_tf = tf.cast(current_loss, dtype=tf.float32)\n",
        "      grads = tape.gradient(current_loss, self.variables)\n",
        "      optimizer.apply_gradients(zip(grads, self.variables),\n",
        "                              global_step=tf.train.get_or_create_global_step())\n",
        "      \n",
        "      \n",
        "  def compute_output(self,X):\n",
        "      conv_layer1 = self.convolution(X, self.W1, self.b1, padding=2, stride=1)\n",
        "      conv_activation = self.relu(conv_layer1)\n",
        "      conv_pool = self.max_pool(conv_activation, pool_h=2, pool_w=2, padding=0, stride=2)\n",
        "      conv_affine =self.affine(conv_pool, self.W2,self.b2)\n",
        "      conv_affine_activation = self.relu(conv_affine)\n",
        "      \n",
        "      conv_affine_1 = self.affine(conv_affine_activation, self.W3, self.b3)\n",
        "      return conv_affine_1\n",
        "    \n",
        "  \n",
        "      \n",
        "      \n",
        "     "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Uw7tXFquhN5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def accuracy_function(yhat,true_y):\n",
        "  correct_prediction = tf.equal(tf.argmax(yhat, 1), tf.argmax(true_y, 1))\n",
        "  accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
        "  return accuracy\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E0VOVUaPkRT0",
        "colab_type": "code",
        "outputId": "8674b9b3-a4a0-427c-b1ed-d2fc04c5af87",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        }
      },
      "source": [
        "# Initialize model using GPU\n",
        "mlp_on_cpu = CNN(hidden_size,output_size, device='gpu')\n",
        "\n",
        "num_epochs = 4\n",
        "train_x =  tf.convert_to_tensor(data.train.images)\n",
        "train_y = tf.convert_to_tensor(data.train.labels)\n",
        "time_start = time.time()\n",
        "num_train = 55000\n",
        "z= 0\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "        train_ds = tf.data.Dataset.from_tensor_slices((data.train.images, data.train.labels)).map(lambda x, y: (x, tf.cast(y, tf.float32)))\\\n",
        "           .shuffle(buffer_size=1000)\\\n",
        "           .batch(batch_size=batch_size)\n",
        "        loss_total = tf.Variable(0, dtype=tf.float32)\n",
        "        accuracy_total = tf.Variable(0, dtype=tf.float32)\n",
        "        for inputs, outputs in train_ds:\n",
        "            preds = mlp_on_cpu.forward(inputs)\n",
        "            loss_total = loss_total + mlp_on_cpu.loss(preds, outputs)\n",
        "#             accuracy_train = accuracy_function(preds,outputs)\n",
        "#             accuracy_total = accuracy_total + accuracy_train\n",
        "            mlp_on_cpu.backward(inputs, outputs)\n",
        "            #print(z)\n",
        "            #z = z+ 1\n",
        "        print('Number of Epoch = {} - loss:= {:.4f}'.format(epoch + 1, loss_total.numpy() / num_train))\n",
        "        preds = mlp_on_cpu.compute_output(train_x)\n",
        "        accuracy_train = accuracy_function(preds,train_y)\n",
        "        \n",
        "        accuracy_train = accuracy_train * 100\n",
        "        print (\"Training Accuracy = {}\".format(accuracy_train.numpy()))\n",
        "        \n",
        "        \n",
        "#         preds_val = mlp_on_cpu.compute_output(data.validation.images)\n",
        "#         accuracy_val = accuracy_function(preds_val,data.validation.labels)\n",
        "#         accuracy_val = accuracy_val * 100\n",
        "#         print (\"Validation Accuracy = {}\".format(accuracy_val.numpy()))\n",
        " \n",
        "#test accuracy\n",
        "test_x =  tf.convert_to_tensor(data.test.images)\n",
        "test_y = tf.convert_to_tensor(data.test.labels)\n",
        "preds_test = mlp_on_cpu.compute_output(test_x)\n",
        "accuracy_test = accuracy_function(preds_test,test_y)\n",
        "# To keep sizes compatible with model\n",
        "accuracy_test = accuracy_test * 100\n",
        "print (\"Test Accuracy = {}\".format(accuracy_test.numpy()))\n",
        "\n",
        "        \n",
        "# time_taken = time.time() - time_start\n",
        "# print('\\nTotal time taken (in seconds): {:.2f}'.format(time_taken))\n",
        "# #For per epoch_time = Total_Time / Number_of_epochs"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/data/util/random_seed.py:58: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "Number of Epoch = 1 - loss:= 0.0360\n",
            "Training Accuracy = 11.234545707702637\n",
            "Number of Epoch = 2 - loss:= 0.0274\n",
            "Training Accuracy = 82.1927261352539\n",
            "Number of Epoch = 3 - loss:= 0.0068\n",
            "Training Accuracy = 88.91090393066406\n",
            "Number of Epoch = 4 - loss:= 0.0053\n",
            "Training Accuracy = 90.74727630615234\n",
            "Test Accuracy = 91.50999450683594\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}